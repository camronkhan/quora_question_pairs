{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import gensim.models.doc2vec as d2v\n",
    "import multiprocessing as mp\n",
    "import datetime as dt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from random import shuffle\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cores = mp.cpu_count() - 2\n",
    "assert d2v.FAST_VERSION > -1, \"Doc2Vec will run painfully slow otherwise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import training data into dataframe\n",
    "questions = pd.read_pickle('./pickles.gi/all_questions_df.pkl')\n",
    "questions = questions.drop('tokens', 1)\n",
    "questions.to_pickle('./pickles.gi/questions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "def preprocessText(questions):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    lowered = [str(question).lower() for question in questions]\n",
    "    tokenized = [tokenizer.tokenize(question) for question in lowered]\n",
    "    filtered = [[token for token in tokens if token not in stopset] for tokens in tokenized]\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>pid</th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>token_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>[story, kohinoor, koh, noor, diamond]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>[would, happen, indian, government, stole, koh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>[increase, speed, internet, connection, using,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test  pid  qid                                           question  \\\n",
       "0     0    0    1  What is the step by step guide to invest in sh...   \n",
       "1     0    0    2  What is the step by step guide to invest in sh...   \n",
       "2     0    1    3  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "3     0    1    4  What would happen if the Indian government sto...   \n",
       "4     0    2    5  How can I increase the speed of my internet co...   \n",
       "\n",
       "                                          token_list  \n",
       "0  [step, step, guide, invest, share, market, india]  \n",
       "1         [step, step, guide, invest, share, market]  \n",
       "2              [story, kohinoor, koh, noor, diamond]  \n",
       "3  [would, happen, indian, government, stole, koh...  \n",
       "4  [increase, speed, internet, connection, using,...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_tokens = questions.copy()\n",
    "preprocessed_tokens['token_list'] = preprocessText(questions['question'])\n",
    "preprocessed_tokens.to_pickle('./pickles.gi/preprocessed_questions.pkl')\n",
    "preprocessed_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatized = [lemmatizer.lemmatize(token) for token in filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get tagged documents\n",
    "train_docs = [d2v.TaggedDocument(row[5], row[1]) for row in preprocessed_tokens.itertuples() if row['test'] == 0]\n",
    "test_docs = [d2v.TaggedDocument(row[5], row[1]) for row in preprocessed_tokens.itertuples() if row['test'] == 1]\n",
    "tagged_docs = train_docs + test_docs\n",
    "doc_list = tagged_docs[:]  # for reshuffling per pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import DBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Model: PV-DM w/average\n",
    "dbow_model = Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\n",
    "# Build vocab table\n",
    "dbow_model.build_vocab(sentences=doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "train_model = dbow_model\n",
    "\n",
    "print(\"START %s\" % dt.datetime.now())\n",
    "\n",
    "for epoch in range(passes):\n",
    "    # shuffling gets best results\n",
    "    shuffle(doc_list)\n",
    "\n",
    "    print ('Training epoch %s' % epoch)\n",
    "\n",
    "    # train\n",
    "    train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "    train_model.train(doc_list)\n",
    "\n",
    "    print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    print(str(dt.datetime.now()))\n",
    "    \n",
    "    alpha -= alpha_delta\n",
    "\n",
    "train_model.save('./models.gi/dbow_model.trained')\n",
    "\n",
    "print(\"END %s\" % str(dt.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
